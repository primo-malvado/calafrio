const brain  = require("brain.js");

// provide optional config object (or undefined). Defaults shown.
const config = {
    binaryThresh: 0.5,
    hiddenLayers: [3],     // array of ints for the sizes of the hidden layers in the network
    activation: 'sigmoid',  // supported activation types: ['sigmoid', 'relu', 'leaky-relu', 'tanh'],
    leakyReluAlpha: 0.01   // supported for activation type 'leaky-relu'
};

// create a simple feed forward neural network with backpropagation
const net = new brain.NeuralNetwork(config);

net.train([{input: [0, 0], output: [0]},
           {input: [0, 1], output: [1]},
           {input: [1, 0], output: [1]},
           {input: [1, 1], output: [0]}], {
		  
   log:  details => console.log(details),
      logPeriod: 10,        // iterations between logging out --> number greater than 0
      learningRate: 0.5,    // scales with delta to effect training rate --> number between 0 and 1
 
      timeout: Infinity,     // the max number of milliseconds to train for --> number greater than 0
 
//  errorThresh: 0.20		   
	 
		   });

const output = net.run([1, 0]);  // [0.987]

	   
	   console.log(output);
	   
/*

var list = [0.84,-1.73,0.27,1.94,-1.12,1.22,2.09,0.07,1.58,0.62,0.02,0.06,-1.13,-0.72,2.27,-0.20,0.46,-0.25,0.41,3.63,2.70,-0.37,-0.68,1.64,-0.90,0.12,1.44,-0.24,-0.91,0.33,1.14,-1.62,0.17,0.17,-1.43,-0.35,1.30,0.71,1.25,0.25,0.52,-0.45,-0.85,1.68,1.38,-0.13,0.53,-0.50,-1.60,-3.91,1.81,0.48,-2.22,-1.55,0.60,-2.77,-0.01,1.61,1.67,0.79,-1.48,-0.01,0.12,1.89,-0.62,1.52,-1.58,-3.05,-0.29,-1.48,-3.38,-0.80,1.51,1.49,-2.85,1.23,-4.08,0.49,0.96,-1.59,1.16,2.57,-1.55,2.05,-1.05,-0.98,1.71,-0.68,-2.71,0.23,-1.44,-1.49,-2.67,-1.07,0.32,-1.01,1.71,2.21,0.08,2.23,0.44,-0.73,2.12,-1.84,-1.09,1.04,0.92,-0.81,3.86,0.10,0.10,0.00,-0.16,-0.96,0.38,-2.10,4.02,1.06,-0.41,0.42,-1.15,0.58,0.14,0.34,0.04,-1.05,0.44,1.08,-1.08,-1.11,-0.52,-2.48,1.45,-1.97,1.53,0.30,1.49,2.35,0.66,-0.44,0.98,2.24,0.64,-0.30,0.01,-0.79,-0.34,0.37,-1.06,-1.53,0.77,-1.96,-1.15,0.21,0.78,0.65,1.03,-1.51,-0.49,-0.02,-0.56,1.01,-1.07,0.92,-0.75,2.71,0.97,0.59,0.30,0.47,-0.71,-0.59,0.44,-1.42,0.13,1.29,-0.29,-1.29,-2.87,-1.91,-0.42,0.10,0.77,0.51,2.24,1.38,-0.13,2.68,-8.07,-1.46,1.76,1.08,1.32,0.11,-0.19,-2.51,-0.54,-0.43,2.52,1.54,1.69,-0.23,1.37,-0.12,0.05,-0.70,1.38,0.00,0.34,0.32,0.70,0.30,0.53,-0.09,-0.40,-1.45,0.64,0.24,1.26,0.65,2.33,-0.31,0.82,-0.24,0.24,-0.67,-0.44,-0.11,-0.37,-0.46,0.70,0.03,-0.78,0.18,0.41,0.78,-0.60,-0.17,1.38,-0.27,0.08,0.47,-0.69,-1.83,0.63,-1.21,-0.48,0.90,-1.58,0.52,0.55,1.02,1.58,-0.56,-2.13,0.11,1.10,-2.15,2.35,0.27,0.42,-0.04,-1.08,1.31,-0.46,-0.24,-0.90,1.30,-0.75,1.13,0.24,0.55,0.09,0.49,-0.04,-0.70,0.09,-0.51,0.29,-1.73,-1.14,-0.72,-0.91,2.56,0.63,1.19,0.12,0.14,0.21,0.43,-0.86,0.65,-0.64,0.47,0.30,-0.59,0.12,0.10,-1.39,0.24,0.37,-1.23,0.37,1.77,1.11,1.98,1.17,0.50,-0.58,1.00,-0.39,1.25,0.13,0.07,0.51,0.05,-0.12,0.05,0.06,-0.20,-0.02,0.08,1.25,-0.01,-0.14,0.30,-0.43,0.14,0.73,-0.78,0.38,-0.44,-0.07,0.64,-0.42,0.39,-0.44,0.53,1.61,0.14,-0.20,-0.82,-1.10,0.65,-0.05,0.04,-1.27,0.39,-0.06,0.81,0.18,0.92,0.18,-0.01,-0.18,0.15,0.30,1.41,0.09,-0.37,-1.04,0.16,-0.18,2.06,-0.23,-0.25,-0.30,-0.19,-0.11,0.35,-0.22,0.39,-0.11,0.55,0.18,-0.01,-0.28,-1.15,0.19,0.72,0.45,-0.34,1.23,0.20,0.46,0.48,-0.27,0.10,-0.98,0.38,0.05,-0.34,-0.06,-0.36,-0.42,-0.74,-0.18,0.55,0.31,3.20,0.07,-0.33,0.10,-0.09,0.72,0.06,0.92,1.38,-0.91,0.35,0.15,-0.23,0.37,0.18,-0.04,-2.00,0.54,0.12,-0.01,0.31,-0.20,-0.17,-0.15,0.18,-0.28,0.34,0.52,1.16,-1.38,0.22,0.28,0.36,-0.55,0.75,0.28,-1.08,0.48,1.18,-0.75,-0.36,0.05,-0.30,0.26,-1.34,0.62,-2.16,-0.21,0.53,-0.02,0.35,-1.08,0.57,0.29,0.22,1.22,0.15,-0.03,-0.53,-1.14,0.35,-0.28,-1.57,-0.03,0.14,-0.04,-0.57,-0.13,-0.61,1.26,-0.56,-0.35,1.24,-0.33,-0.09,-0.50,-1.81,0.35,1.37,0.32,0.26,-0.90,0.33,-0.74,1.50,-0.55,-0.05,-0.07,-0.33,-1.19,0.32,0.33,0.71,-0.20,-0.45,1.78,0.29,-0.26,1.65,0.20,0.24,-0.01,-0.08,0.21,-0.04,0.65,-0.33,0.13,-0.31,0.19,0.65,0.29,1.00,0.52,0.25,0.31,-0.11,-0.20,0.13,0.10,0.03,0.14,0.05,0.06,0.38,-0.49,-0.04,-0.03,0.25,-0.36,1.46,0.45,0.09,0.00,1.80,-0.06,0.14,-0.06,-0.74,0.15,-1.53,-0.45,-0.14,-0.54,-0.61,0.99,-0.83,0.59,0.93,-1.51,0.24,0.46,-0.44,0.83,-0.43,-0.11,-0.78,0.66,-0.19,-0.04,0.73,0.51,-0.07,0.13,-0.72,-0.35,0.69,1.46,-0.56,-1.25,0.00,0.03,-0.12,-0.57,-0.97,0.23,0.96,1.21,1.27,0.23,0.19,-0.95,-0.12,-0.07,-0.33,-0.36,0.69,0.35,1.36,-0.28,-0.80,0.52,-0.59,-0.84,0.01,-1.78,-1.98,-3.50,3.08,-0.87,-3.20,0.62,1.16,-0.76,1.33,-0.46,1.04,-0.74,0.31,-0.31,0.25,0.96,0.32,-1.21,-0.52,-2.45,-0.51,1.41,-0.10,0.86,0.63,0.27,0.23,-1.98,0.84,1.03,0.07,-1.19,0.77,-0.65,-2.22,-1.73,1.16,-0.56,0.76,1.49,-0.53,0.12,1.76,-0.80,0.43,1.19,-0.84,1.23,0.16,-0.24,1.33,0.09,-0.29,-0.23,0.32,-1.00,0.04,0.91,0.22,-0.15,1.74,-0.33,0.73,0.68,0.07,0.32,0.38,-0.32,-0.13,0.17,0.20,0.67,-0.26,0.66,-1.17,-0.89,0.33,-0.56,-1.68,1.29,-1.37,0.91,0.28,-0.12,1.01,-1.38,0.56,0.71,-0.25,0.11,2.20,-0.65,-1.55,-1.03,-0.15,-1.74,0.57,-2.08,0.03,-0.14,-0.44,0.50,0.10,0.07,0.22,1.17,0.15,0.57,0.29,-1.47,0.71,0.32,0.24,1.02,0.39,-0.55,-1.12,0.25,0.81,0.35,0.66,-0.19,0.25,-0.64,-0.96,0.26,-0.27,0.45,-0.41,0.54,-2.10,-0.45,0.46,-2.01,0.53,0.03,0.68,0.58,-0.08,-0.12,0.33,1.22,-0.15,0.30,-0.96,-0.80,-0.07,-0.93,-1.33,-0.62,-0.37,0.48,-0.04,0.11,0.60,0.32,-0.55,0.96,0.43,1.07,0.45,-0.46,0.18,-0.26,0.56,-1.48,0.68,-0.28,-0.41,-1.04,-1.00,-0.13,-3.30,0.43,-0.03,1.64,-0.58,-1.73,0.14,-0.18,-1.21,-2.85,2.18,-0.96,0.52,1.17,0.32,0.50,0.64,-0.43,0.27,1.02,-1.18,0.19,-2.02,0.97,-0.08,0.40,-0.69,-1.42,-1.28,1.54,-0.77,0.27,1.77,-0.45,0.70,-0.69,-0.10,1.41,-2.75,0.26,-2.26,-2.03,0.05,0.77,1.17,-0.23,-0.72,-0.97,0.33,-0.92,-1.14,-0.06,-0.49,1.01,0.54,-2.00,3.63,-0.62,1.01,0.43,0.75,-0.72,-0.20,0.35,0.10,0.29,2.54,-0.77,-1.02,0.34,0.78,0.86,-0.16,-0.25,0.01,-0.16,-0.02,0.10,1.48,-0.54,-2.37,-0.73,0.49,1.23,0.35,-0.80,2.06,-0.11,0.03,0.92,-0.09,0.46,0.07,0.57,-0.40,0.32,0.95,-0.62,0.53,-0.47,-0.65,0.00,0.90,-0.68,0.76,-0.11,0.85,-0.20,0.70,-1.45,0.09,-2.21,0.33,0.67,0.02,0.24,0.67,1.43,0.70,1.30,0.31,0.13,-0.41,-0.84,0.51,0.18,0.68,0.06,0.60,0.68,0.61,0.55,-0.06,0.18,0.12,0.14,-0.27,0.95,-0.93,-2.12,0.97,-1.82,1.84,-2.64,0.94,0.95,1.46,-0.61,-1.33,0.99,-0.10,-1.57,0.59,0.35,-0.75,-0.95,0.52,-1.52,2.13,0.01,-0.03,0.53,0.33,0.46,-0.37,0.50,-0.46,-0.20,2.08,-0.20,0.47,-0.83,-0.21,-0.52,0.48,0.32,0.95,1.14,0.06,0.85,-0.15,-0.47,-0.53,-0.40,-0.57,-0.34,0.51,0.16,-0.94,-0.50,-0.04,0.50,1.95,0.21,-1.69,0.59,-0.05,-2.41,0.15,-0.56,-1.38,-2.42,0.15,0.72,0.93,-0.83,-0.86,1.37,-2.99,-0.21,1.33,1.11,-0.65,1.44,-0.26,-1.85,1.25,0.22,-0.15,1.40,0.83,-0.12,-0.18,0.98,0.72,0.45,0.37,0.58,0.71,0.27,0.34,-0.53,-0.46];





var len = 8;
const config = {
    //inputSize: 24,
   // inputRange: 20,
    hiddenLayers: [7],
  //  outputSize: 1,
    learningRate: 0.1,
    //decayRate: 0.999,
 activation: 'sigmoid', 
};

// create a simple feed forward neural network with backpropagation
const net = new brain.NeuralNetwork(config);

 




  
var trainData = [];
for(var i = 0; i< list.length-150; i = i+2)
{
   var a = list.filter(function(a,index, c, d){
 

		return index > i && index < i+len;
	});
	
	trainData.push({input: a , output: [ list[i+len]  ]});

}


console.log(trainData);



net.train(trainData, {
   //   iterations: 100000,    // the maximum times to iterate the training data --> number greater than 0
          log:  details => console.log(details),
      logPeriod: 10,        // iterations between logging out --> number greater than 0
      learningRate: 0.5,    // scales with delta to effect training rate --> number between 0 and 1
 
      timeout: Infinity,     // the max number of milliseconds to train for --> number greater than 0
	
	
	
	
  //iterations: 10000,
  //log: details => console.log(details),
  errorThresh: 0.20
	});




var pos = 985; var test = list.filter(function(a,index, c, d){return index > pos-(len) && index < pos;}); //console.log(test)
var output = net.run(test);  // list[pos] = 1.4
console.log(list[pos], output);



  pos = 976; var test = list.filter(function(a,index, c, d){return index > pos-(len) && index < pos;}); //console.log(test)
  output = net.run(test);  // list[pos] = 1.4
console.log(list[pos], output);


  pos = 968; var test = list.filter(function(a,index, c, d){return index > pos-(len) && index < pos;}); //console.log(test)
  output = net.run(test);  // list[pos] = 1.4
console.log(list[pos], output);

*/

